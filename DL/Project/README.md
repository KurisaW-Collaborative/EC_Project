# 此处用于笔记存放

---

## 1.K折交叉验证法

在简单的交叉验证过程中，我们已经把原数据划分为训练集、验证集和测试集，但由于并不是所有的数据都参与了模型训练（至少验证集没有），因此就存在数据信息利用不全的弊端；此外，不同的划分结果也会导致模型不同的训练效果。

为了确保泛化误差的稳定性，从而得到理想的模型，我们就需要利用K折验证法，其一般流程如下：

**(1) 将数据集分为训练集和测试集，测试集放在一边。**

**(2) 将训练集分为 k 份，每次使用 k 份中的1 份作为验证集，其他全部作为训练集。**

(**3) 通过 k 次训练后，得到了 k 个不同的模型。**

**(4) 评估 k 个模型的效果，从中挑选效果最好的超参数。**

**(5) 使用最优的超参数，然后将 k 份数据全部作为训练集重新训练模型，得到最终所需模型，最后再到测试集上测试。**